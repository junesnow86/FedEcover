dropout_rate: 0.8

Original model test loss: 0.082528, accuracy: 0.095400, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.007, 6: 0.0, 7: 0.927, 8: 0.0, 9: 0.02}
--------------------------------------------------------------------------------
Round 1/10
Pruned model 1 test loss: 0.070311, accuracy: 0.339500, class accuracy: {0: 0.786, 1: 0.861, 2: 0.416, 3: 0.603, 4: 0.729, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.093187, accuracy: 0.385600, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.805, 6: 0.756, 7: 0.676, 8: 0.854, 9: 0.765}
Aggregated model test loss: 0.017490, accuracy: 0.251900, class accuracy: {0: 0.226, 1: 0.167, 2: 0.103, 3: 0.462, 4: 0.0, 5: 0.139, 6: 0.01, 7: 0.625, 8: 0.111, 9: 0.676}
--------------------------------------------------------------------------------
Round 2/10
Pruned model 1 test loss: 0.051871, accuracy: 0.356600, class accuracy: {0: 0.816, 1: 0.851, 2: 0.63, 3: 0.677, 4: 0.592, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.055433, accuracy: 0.402800, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.834, 6: 0.774, 7: 0.788, 8: 0.88, 9: 0.752}
Aggregated model test loss: 0.013357, accuracy: 0.396400, class accuracy: {0: 0.5, 1: 0.558, 2: 0.514, 3: 0.498, 4: 0.031, 5: 0.168, 6: 0.22, 7: 0.561, 8: 0.325, 9: 0.589}
--------------------------------------------------------------------------------
Round 3/10
Pruned model 1 test loss: 0.051456, accuracy: 0.364300, class accuracy: {0: 0.749, 1: 0.902, 2: 0.504, 3: 0.692, 4: 0.796, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.050204, accuracy: 0.414900, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.84, 6: 0.876, 7: 0.715, 8: 0.888, 9: 0.83}
Aggregated model test loss: 0.012693, accuracy: 0.426900, class accuracy: {0: 0.622, 1: 0.688, 2: 0.521, 3: 0.611, 4: 0.293, 5: 0.131, 6: 0.229, 7: 0.36, 8: 0.289, 9: 0.525}
--------------------------------------------------------------------------------
Round 4/10
Pruned model 1 test loss: 0.055948, accuracy: 0.371800, class accuracy: {0: 0.766, 1: 0.867, 2: 0.692, 3: 0.727, 4: 0.666, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.045007, accuracy: 0.421400, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.824, 6: 0.843, 7: 0.774, 8: 0.912, 9: 0.861}
Aggregated model test loss: 0.012574, accuracy: 0.432000, class accuracy: {0: 0.684, 1: 0.733, 2: 0.603, 3: 0.653, 4: 0.32, 5: 0.159, 6: 0.211, 7: 0.263, 8: 0.262, 9: 0.432}
--------------------------------------------------------------------------------
Round 5/10
Pruned model 1 test loss: 0.051570, accuracy: 0.378200, class accuracy: {0: 0.822, 1: 0.875, 2: 0.643, 3: 0.771, 4: 0.671, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.043448, accuracy: 0.416400, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.877, 6: 0.899, 7: 0.644, 8: 0.907, 9: 0.837}
Aggregated model test loss: 0.012115, accuracy: 0.443100, class accuracy: {0: 0.698, 1: 0.695, 2: 0.546, 3: 0.689, 4: 0.336, 5: 0.22, 6: 0.352, 7: 0.185, 8: 0.287, 9: 0.423}
--------------------------------------------------------------------------------
Round 6/10
Pruned model 1 test loss: 0.054573, accuracy: 0.379800, class accuracy: {0: 0.829, 1: 0.923, 2: 0.652, 3: 0.786, 4: 0.608, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.046404, accuracy: 0.424800, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.839, 6: 0.905, 7: 0.76, 8: 0.886, 9: 0.858}
Aggregated model test loss: 0.011795, accuracy: 0.465600, class accuracy: {0: 0.681, 1: 0.773, 2: 0.513, 3: 0.592, 4: 0.397, 5: 0.334, 6: 0.498, 7: 0.159, 8: 0.332, 9: 0.377}
--------------------------------------------------------------------------------
Round 7/10
Pruned model 1 test loss: 0.055174, accuracy: 0.386200, class accuracy: {0: 0.807, 1: 0.907, 2: 0.614, 3: 0.749, 4: 0.785, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.044783, accuracy: 0.426700, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.801, 6: 0.904, 7: 0.807, 8: 0.937, 9: 0.818}
Aggregated model test loss: 0.011601, accuracy: 0.475300, class accuracy: {0: 0.592, 1: 0.743, 2: 0.53, 3: 0.554, 4: 0.547, 5: 0.355, 6: 0.422, 7: 0.133, 8: 0.483, 9: 0.394}
--------------------------------------------------------------------------------
Round 8/10
Pruned model 1 test loss: 0.052153, accuracy: 0.385300, class accuracy: {0: 0.81, 1: 0.914, 2: 0.69, 3: 0.75, 4: 0.689, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.047719, accuracy: 0.428300, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.864, 6: 0.838, 7: 0.795, 8: 0.928, 9: 0.858}
Aggregated model test loss: 0.011247, accuracy: 0.482400, class accuracy: {0: 0.445, 1: 0.72, 2: 0.409, 3: 0.472, 4: 0.444, 5: 0.502, 6: 0.559, 7: 0.2, 8: 0.572, 9: 0.501}
--------------------------------------------------------------------------------
Round 9/10
Pruned model 1 test loss: 0.050257, accuracy: 0.385000, class accuracy: {0: 0.811, 1: 0.943, 2: 0.689, 3: 0.78, 4: 0.627, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.047332, accuracy: 0.432300, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.825, 6: 0.879, 7: 0.803, 8: 0.949, 9: 0.867}
Aggregated model test loss: 0.010890, accuracy: 0.497900, class accuracy: {0: 0.487, 1: 0.717, 2: 0.452, 3: 0.436, 4: 0.385, 5: 0.529, 6: 0.578, 7: 0.28, 8: 0.586, 9: 0.529}
--------------------------------------------------------------------------------
Round 10/10
Pruned model 1 test loss: 0.051904, accuracy: 0.385600, class accuracy: {0: 0.821, 1: 0.874, 2: 0.694, 3: 0.785, 4: 0.682, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}
Pruned model 2 test loss: 0.047004, accuracy: 0.432400, class accuracy: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.793, 6: 0.895, 7: 0.822, 8: 0.939, 9: 0.875}
Aggregated model test loss: 0.011800, accuracy: 0.474000, class accuracy: {0: 0.548, 1: 0.649, 2: 0.525, 3: 0.472, 4: 0.473, 5: 0.434, 6: 0.442, 7: 0.17, 8: 0.501, 9: 0.526}
--------------------------------------------------------------------------------
